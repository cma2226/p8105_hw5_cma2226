---
title: "Data Science HW 5"
author: "Caroline Andy"
date: "11/15/2020"
output: html_document
---

### Problem 1

```{r 1}
#generate homicide table and summarize solved and unsolved murders by state
library(readr)
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide = read_csv(url(urlfile)) %>%
  mutate(city_state = paste(city, state)) %>%
  mutate(outcome = case_when(disposition %in% "Closed without arrest" ~ "unsolved",
                             disposition %in% "Closed by arrest" ~ "solved", 
                             disposition %in% "Open/No arrest" ~ "unsolved")) %>%
  group_by(city_state, outcome) %>%
  summarize(n_obs = n())

# prop test for Baltimore
baltimore = homicide %>%
  filter(city_state == "Baltimore MD") %>%
  pivot_wider(names_from = "outcome", values_from = "n_obs") %>%
  mutate(total = solved + unsolved)

baltimore_test = prop.test(x = baltimore$unsolved, n = baltimore$total) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high) %>%
  mutate(conf_int = paste(round(conf.low, 6), sep = " - ", round(conf.high, 6))) %>%
  select(estimate, conf_int)

# prop test for all cities
homicide = homicide %>%
  pivot_wider(names_from = "outcome", values_from = "n_obs") %>%
  mutate(total = solved + unsolved) 

prop_test = function(city_state) {
  
  df = prop.test(x = homicide$unsolved, n = homicide$total) %>%
    broom::tidy() 
    
}

output = map_df(.x = homicide, ~ prop_test(.x))

```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.



### Problem 2

```{r 2i}
library(stringr)
path_df = 
  tibble(
    path = list.files("data")
  )

path_df = path_df %>%
  mutate(
    path = str_c("data/", path),
    data = map(.x = path, ~read_csv(.x))
  ) %>%
  unnest(data) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation"
  ) %>%
  mutate(
    week = as.numeric(str_replace(week, "week_", "")),
    arm = str_extract(path, "/[a-z][a-z][a-z]"),
    arm = str_remove(arm, "/"),
    id = str_extract(path, "[0-9]+")
  ) %>%
  select(-path)
```

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r 2ii}
path_df %>%
  ggplot(aes(x = week, y = observation, color = id, linetype = arm)) + 
  geom_line() +
  labs(
    title = "Observations for Each Subject by Week",
    x = "Week Number",
    y = "Observation",
    caption = "Data from subjects enrolled in a longitudinal study. Subjects 01 through 05 were enrolled in the control arm, \nand subjects 06 through 10 in the experimental arm"
  )
```

### Problem 3

```{r simulate}
sim_mean_sd = function(n = 30, mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = sigma),
  ) 
  
  sim_data %>%
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x)
    )
}

output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_mean_sd(30)
}

sim_results = bind_rows(output)


```


For each dataset, save μ̂  and the p-value arising from a test of H:μ=0 using α=0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.

Repeat the above for μ={1,2,3,4,5,6}, and complete the following:

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

Make a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

